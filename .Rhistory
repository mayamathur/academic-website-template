cardio = sum(c(75,30,30,43, 45, 144))/60
cardio
lift = sum(c(3,60,20,35,31))/60
lift
library(scholar)
library(ggplot2)
library(dplyr)
# MY PUBS ------------------------------------
# retrieve all my publications, including their Google Scholar article IDs
myID = "vmuNN1sAAAAJ"
myPubs <- get_publications(myID)
myPubs = myPubs[ order(myPubs$year), ]
View(myPubs)
cardio = sum(c(70,40,47,47,151))
cardio = cardio+30
cardio/60
lift = sum(c(56,20,20,38,33))/60
lift
# make df defining the order of plots that should be in Supplement
df = expand_grid( trunc.type = c("single", "double-symm", "double-asymm"),
estName = estNames,
outcomeName = outcomeNames )
fig.strings = paste( df$trunc.type,
"_",
tolower(df$estName),
"_n_",
tolower(df$outcomeName),
"_plot.pdf",
sep = "" )
# \figcoef should be def'd in the Overleaf document to control all figures
width.string = "\\figcoef\\textwidth"
caption.strings = paste("\\caption{\\label{sfig:",
df$trunc.type,
"_",
tolower(df$estName),
"_",
tolower(df$outcomeName),
"}}",
sep = "" )
for ( i in 1:length(fig.strings) ) {
# structure of fig names taken from plot_by_n
cat( "\\begin{figure}[H] \\centering \\includegraphics[width=",
width.string,
"]{R_objects/figures/",
fig.strings[i],
"}",
caption.strings[i],
"\\end{figure}",
sep = "" )
cat("\n\n")
}
cardio = sum(c(75,41,48,40,124,30,51))/60
cardoi
cardio
lift = sum(c(10,21,25,3,18,20,39,30))/60
lift
(29+83)/502
(65+51+51+19+14)/502
189/502
cardio = sum(c(76,40,69,120,56))/60
cardio
lift = sum(c(30,18,27,3,57))/60
lift
cardio = sum(c(74,43,33,41,120))/60
cardio
mi= 7.4+5+9
mi
cardio = cardio + (51/60)
cardio
21.4+5.2
lift = sum(c(18,53,3,23,43,38))
lift/60
cardio = sum(c(74,43,33,41,120,51,25))/60
cardio
lift = sum(c(18,53,3,23,43,38,50))
lift/60
x = c(50,1323,1887,1891)
x/sum(x)
cardio = sum(c(45,60,34,45,120))/60
cardio
cardio = sum(c(45,60,34,45,120,41))/60
cardio
cardio = sum(c(45,60,34,45,120,41,60))/60
cardio
lift = sum(c(15,25,3,23,36,30,38,20,17,3))
lift/60
?PublicationBias
library(PublicationBias)
?svalue
x = c(283,271,308)
chisq.test(x)
exp(.1)
exp(-0.48)
# PRELIMINARIES ----------------------------------
library(scholar)
library(ggplot2)
library(dplyr)
library(stringr)
library(here)
library(directlabels)
library(plotly)
results.dir = here()
card = 5.26+1
card
6014.79*4
(6014.79*4)/188000
188000/4
.07*47000
75/200
164.87/(203000/4)
card = sum(c(74,50,43,41,122))/60
cardio
card
card = card+.75
card
card = sum(c(74,50,43,41,122,45))
card/60
card = card+33
card/60
10+5.2+14+4
sum(c(31,27,3,27,32,47,23,27))/60
card = sum(c(70,55,38,31,133))
card/60
library(devtools)
install_github("metacran/cranlogs")
library(cranlogs)
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "EValue"
d = cran_downloads(from = "2021-01-01",
to = "2021-12-31",
package = package)
library(ggplot2)
ggplot( data = d, aes( x = date, y = count, color = package) ) +
geom_line() +
geom_hline( yintercept = median(d$count), lty = 2, color = "red" ) +
ylab("Daily downloads") +
theme_classic()
library(devtools)
install_github("metacran/cranlogs")
library(devtools)
install_github("metacran/cranlogs")
library(cranlogs)
#package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
package = "EValue"
# d = cran_downloads(from = "2019-01-01",
#                    to = "2019-12-31",
#                    package = package)
d = cran_downloads(from = "2021-01-01",
to = "2021-12-31",
package = package)
library(ggplot2)
ggplot( data = d, aes( x = date, y = count, color = package) ) +
geom_line() +
geom_hline( yintercept = median(d$count), lty = 2, color = "red" ) +
ylab("Daily downloads") +
theme_classic()
# total for the year
sum(d$count)
package = c( "EValue", "SimTimeVar", "NRejections", "MetaUtility", "Replicate", "PublicationBias" )
d = cran_downloads(from = "2021-01-01",
to = "2021-12-31",
package = package)
# count by package
library(dplyr)
d %>% group_by(package) %>%
summarise( yr.total = sum(count) ) %>%
arrange( desc(yr.total) )
package = "phacking"
d = cran_downloads(from = "2022-01-01",
to = "2022-12-31",
package = package)
d %>% group_by(package) %>%
summarise( yr.total = sum(count) ) %>%
arrange( desc(yr.total) )
card = sum(c(70,50,50,52,132,20))
card/60
card = sum(c(70,50,50,52,132,20,51))
card/60
sum(c(39,30,30,13,36,18))
166/60
# This script uses renv to preserve the R environment specs (e.g., package versions.)
library(renv)
# run this if you want to reproduce results using the R environment we had:
# renv::restore()
# data-wrangling packages
library(dplyr)
library(tibble)
library(ggplot2)
library(data.table)
library(stringr)
library(tidyverse)
library(fastDummies)
# meta-analysis packages
library(metafor)
library(robumeta)
# other
library(here)
library(xtable)
library(testthat)
# GET DATA ---------------------------------------------------------------
setwd(here())
d = fread("Raw data/Data Collection Sheet - Main Data Tab.csv")
d = d %>% rename(treat = Treatment,
meat = Meat,
stat2_meat_lb = `Quantity of Meat Served (Station 1) lbs`,
stat1_meat_lb = `Quantity of Meat Served (Station 2) lbs`,
meat_lb = `Quantity of Meat Served at Cardinal Sage lbs`)
# exclude the day when only 1 station was open
d = d %>% filter( stat1_meat_lb != "N/A (There was only one station open today)" )
head(d)
c(.85, .95, 1.1, .5)*220
3*220
1.2*220
1.12*220
.63*220
64/(64+7)
# Peloton -> Zwift conversion
ftp1 = 1353   # Pelton
ftp2 = 225  # Zwift
# Peloton
zone.midpoints.1 = c( mean(977,1050), mean(1175,1275), mean(1275,1375), mean(1375,1425), mean(1425,1525 ) )
(zone.midpoints.1/ftp)
ftp1 = 1353   # Peloton
ftp2 = 225  # Zwift
# Peloton
zone.midpoints.1 = c( mean(977,1050), mean(1175,1275), mean(1275,1375), mean(1375,1425), mean(1425,1525 ) )
zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1)
( zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1) )
zone.midpoints.1
# Peloton
zone.midpoints.1 = c( mean( c(977,1050)), mean(c(1175,1275)), mean(c(1275,1375)), mean(c(1375,1425)), mean(c(1425,1525) ) )
# Peloton
( zone.midpoints.1 = c( mean( c(977,1050)), mean(c(1175,1275)), mean(c(1275,1375)), mean(c(1375,1425)), mean(c(1425,1525) ) ) )
( zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1) )
ftp2 = 214  # Zwift
# Peloton
( zone.midpoints.1 = c( mean( c(977,1050)), mean(c(1175,1275)), mean(c(1275,1375)), mean(c(1375,1425)), mean(c(1425,1525) ) ) )
( zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1) )
ftp2 = 220  # Zwift
# Peloton
( zone.midpoints.1 = c( mean( c(977,1050)), mean(c(1175,1275)), mean(c(1275,1375)), mean(c(1375,1425)), mean(c(1425,1525) ) ) )
( zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1) )
# Peloton -> Zwift conversion
ftp1 = 1353   # Peloton
ftp2 = 220  # Zwift
# Peloton
( zone.midpoints.1 = c( mean( c(977,1050)), mean(c(1175,1275)), mean(c(1275,1375)), mean(c(1375,1425)), mean(c(1425,1525) ) ) )
( zone.midpoints.2 = ftp2 * (zone.midpoints.1/ftp1) )
mean(c(165,200))
sum(c(44,120,25,30,43,25,65))/60
exp(-20)
exp(-10)
exp(-5)
sum(c(38,30,43,20,42,38,15,12))/60
card = sum(c(70,47,44,45,122,47))
card/60
card = sum(c(70,47,44,45,122,47,46))
card/60
95/60
sum(c(37,35,38,30,36,16,20))
sum(c(37,35,38,30,36,16,20))/60
sum(c(37,35,38,30,36,20,20))/60
library(robumeta)
d = data.frame( yi = 0.3,
vi = 0.4 )
d1 = data.frame( yi = 0.3,
vi = 0.4 )
library(robumeta)
d1 = data.frame( cluster = 1,
yi = 0.3,
vi = 0.4 )
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d1 )
d1 = data.frame( cluster = c(1, 2),
yi = c(0.3, -0.1),
vi = c(0.4, 0.3) )
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d1 )
d1 = data.frame( cluster = c( rep(1, 4), 2),
yi = c( rep(0.3, 4), -0.1),
vi = c( rep(0.4, 4), 0.3) )
d2 = data.frame( cluster = c( rep(1, 4), 2),
yi = c( rep(0.3, 4), -0.1),
vi = c( rep(0.4, 4), 0.3) )
d2
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d1 )
n_repeated = 10
d2 = data.frame( cluster = c( rep(1, n_repeated), 2),
yi = c( rep(0.3, n_repeated), -0.1),
vi = c( rep(0.4, n_repeated), 0.3) )
n_repeated = 10
d2 = data.frame( cluster = c( rep(1, n_repeated), 2),
yi = c( rep(0.3, n_repeated), -0.1),
vi = c( rep(0.4, n_repeated), 0.3) )
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d1 )
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d2 )
d1 = data.frame( cluster = c(1, 2),
yi = c(0.3, -0.1),
vi = c(0.4, 0.3) )
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d1 )
dim(d1)
dim(d2)
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d2 )
n_repeated = 100
d2 = data.frame( cluster = c( rep(1, n_repeated), 2),
yi = c( rep(0.3, n_repeated), -0.1),
vi = c( rep(0.4, n_repeated), 0.3) )
dim(d2)
robu(yi ~ 1,
var.eff.size = vi,
studynum = cluster,
data = d2 )
41/354
lift = sum(c(30,39,23,41,30))
lift/60
card = sum(c(48,49,49,120,50))
card/60
card = sum(c(48,49,49,120,50,53))
card/60
lift = sum(c(30,39,23,41,30,20))
lift/60
5.05+4.68+4.72
x1 = seq(1200,1450, 25)
x1/1353
x1*220
(x1/1353)*220
d = data.frame(x1, x2 = (x1/1353)*220)
d
d$ratio = x1/1353
d
x1 = seq(1200,1550, 25)
rat = x1/1353
d = data.frame( ratio = round(rat, 2), spin_bike = x1, zwift = round((x1/1353)*220, 0) )
d
x1 = seq(1200,1600, 25)
rat = x1/1353
d = data.frame( ratio = round(rat, 2), spin_bike = x1, zwift = round((x1/1353)*220, 0) )
d
46/134
34/134
# This script uses renv to preserve the R environment specs (e.g., package versions.)
library(renv)
# run this if you want to reproduce results using the R environment we had:
# renv::restore()
# data-wrangling packages
library(dplyr)
library(tibble)
library(ggplot2)
library(data.table)
library(stringr)
library(tidyverse)
library(fastDummies)
# meta-analysis packages
library(metafor)
library(robumeta)
# other
library(here)
library(xtable)
library(testthat)
# GET DATA ---------------------------------------------------------------
setwd(here())
d = fread("Raw data/Data Collection Sheet - Main Data Tab.csv")
d = d %>% rename(treat = Treatment,
meat = Meat,
stat2_meat_lb = `Quantity of Meat Served (Station 1) lbs`,
stat1_meat_lb = `Quantity of Meat Served (Station 2) lbs`,
meat_lb = `Quantity of Meat Served at Cardinal Sage lbs`)
# exclude the day when only 1 station was open
d = d %>% filter( stat1_meat_lb != "N/A (There was only one station open today)" )
m = lm( meat_lb ~ treat + meat, data = d)
summary(m)
# This script uses renv to preserve the R environment specs (e.g., package versions.)
library(renv)
# run this if you want to reproduce results using the R environment we had:
# renv::restore()
# data-wrangling packages
library(dplyr)
library(tibble)
library(ggplot2)
library(data.table)
library(stringr)
library(tidyverse)
library(fastDummies)
# meta-analysis packages
library(metafor)
library(robumeta)
# other
library(here)
library(xtable)
library(testthat)
# GET DATA ---------------------------------------------------------------
setwd(here())
d = fread("Raw data/Data Collection Sheet - Main Data Tab.csv")
d = d %>% rename(treat = Treatment,
meat = Meat,
stat2_meat_lb = `Quantity of Meat Served (Station 1) lbs`,
stat1_meat_lb = `Quantity of Meat Served (Station 2) lbs`,
meat_lb = `Quantity of Meat Served at Cardinal Sage lbs`)
# exclude the day when only 1 station was open
d = d %>% filter( stat1_meat_lb != "N/A (There was only one station open today)" )
setwd(here())
getwd()
card = sum(c(66,49,45,49,100))
card/60
card = sum(c(66,49,45,49,100,44,51)
)
card/60
lift = sum(c(41,33,39,13,30,44))
lift/60
